{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NPG, TRPO, ACER, PPO, ACKTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, argus, alpha, beta, rv_continuous, rv_discrete\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from gym import Wrapper\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from itertools import count\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_softmax(x, sf=1, mag=2, shift=1):\n",
    "    return 1/(1 + np.exp(-x * sf)) * mag - shift\n",
    "def p_tanh(x, power=3, expl=0.001, mag=1, shift=0):\n",
    "    return np.tanh(np.power(x, power) * expl) * mag - shift\n",
    "def t_power(x, power=2, expl=0.5, mag=2, shift=1):\n",
    "    return np.tanh(np.sign(x) * np.power(x, power) * expl) * mag - shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent():\n",
    "    def _set_seed(self, seed, env):\n",
    "        env.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    def _extract_x(self, X):\n",
    "        seed,  environments = X[0]\n",
    "        environments = {\n",
    "            env.env.unwrapped.__class__.__name__:{'env':env} for env in environments\n",
    "        }\n",
    "        return seed, environments\n",
    "\n",
    "    def fit(self, X):\n",
    "        seed, environments = self._extract_x(X)\n",
    "        self.results = {}\n",
    "        for env_name, env_data in environments.items():\n",
    "            env = env_data['env'].env\n",
    "            gamma = env_data['env'].gamma\n",
    "            max_episodes = env_data['env'].max_episodes\n",
    "            goal_mean_reward = env_data['env'].goal_mean_reward\n",
    "            self._set_seed(seed, env)\n",
    "            print('Training on {} environment with seed {} and params {}'.format(env_name, seed, self.params))\n",
    "            self.results[env_name] = self.train(env, gamma, max_episodes, goal_mean_reward)\n",
    "        return self.results\n",
    "\n",
    "    def score(self, X):\n",
    "        seed, environments = self._extract_x(X)\n",
    "        total_score = 0\n",
    "        for env_name, env_data in environments.items():\n",
    "            env = env_data['env'].env\n",
    "            self._set_seed(seed, env)\n",
    "            \n",
    "            policy = self.results[env_name]['policy']\n",
    "            e_mean_reward = self.evaluate(env, policy)\n",
    "            t_episodes = self.results[env_name]['training_episodes']\n",
    "            t_episodes_weight = env_data['env'].training_episodes_weight\n",
    "            t_mean_reward = self.results[env_name]['training_mean_reward']\n",
    "            t_mean_reward_weight = env_data['env'].training_mean_reward_weight\n",
    "            e_mean_reward_weight = env_data['env'].evaluation_mean_reward_weight\n",
    "            goal_mean_reward = env_data['env'].goal_mean_reward\n",
    "\n",
    "            e_mean_reward_score = c_softmax(e_mean_reward / goal_mean_reward - 1, 50)\n",
    "            w_e_mean_reward_score = e_mean_reward_score * e_mean_reward_weight\n",
    "            \n",
    "            t_mean_reward_bonus = c_softmax(t_mean_reward / goal_mean_reward - 1, 50)\n",
    "            w_t_mean_reward_bonus = t_mean_reward_bonus * t_mean_reward_weight\n",
    "            \n",
    "            t_episodes_bonus = t_power(env_data['env'].max_episodes/t_episodes - 1)\n",
    "            w_t_episodes_bonus = t_episodes_bonus * t_episodes_weight\n",
    "            \n",
    "            score = w_e_mean_reward_score + w_t_episodes_bonus + w_t_mean_reward_bonus\n",
    "\n",
    "            print(\"Score in the {} environment with seed {}:\"\n",
    "                  \"\\nAgent = {}\"\n",
    "                  \"\\nScore = {}. Breakdown:\"\n",
    "                  \"\\n\\tEvaluation mean reward = {}, normalized = {}, weighted = {}\"\n",
    "                  \"\\n\\tTraining mean reward = {}, normalized = {}, weighted = {}\"\n",
    "                  \"\\n\\tTraining episodes = {}, normalized = {}, weighted = {}\"\n",
    "                  \"\".format(env_name, seed, \n",
    "                            self,\n",
    "                            score,\n",
    "                            e_mean_reward, e_mean_reward_score, w_e_mean_reward_score,\n",
    "                            t_mean_reward, t_mean_reward_bonus, w_t_mean_reward_bonus,\n",
    "                            t_episodes, t_episodes_bonus, w_t_episodes_bonus))\n",
    "            total_score += score\n",
    "\n",
    "        print('Total score across all environments for seed {} = {}'.format(seed, total_score))\n",
    "        print('---------------------------------------------\\n')\n",
    "        return total_score\n",
    "    \n",
    "    def demo(self, environment, results):\n",
    "        self.evaluate(env=environment.env, episodes=1, \n",
    "                      policy=results[environment.get_environment_name()]['policy'], \n",
    "                      render=True)\n",
    "        \n",
    "    def get_params(self, deep=False):\n",
    "        return self.params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.params = {\n",
    "            k:v for k, v in params.items()\n",
    "        }\n",
    "        for k, v in self.params.items():\n",
    "            setattr(self, k, v)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        params_str = ', '.join([str(k) + '=' + str(v) for k, v in self.params.items()])\n",
    "        return '%s(%s)' % (class_name, params_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearning(BaseAgent):\n",
    "    def __init__(self):\n",
    "        self.params = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def train(self, env, gamma, max_episodes, goal_mean_reward):\n",
    "        nS, nA = env.observation_space.n, env.action_space.n\n",
    "        Q = np.zeros((nS, nA))\n",
    "\n",
    "        rewards = []\n",
    "        with tqdm(total=max_episodes) as pbar:\n",
    "            for e in range(max_episodes):\n",
    "                state, done = env.reset(), False\n",
    "                self.behavioral_strategy.reset()\n",
    "                rewards.append(0)\n",
    "                while not done:\n",
    "                    action = self.behavioral_strategy.select_action(Q[state])\n",
    "                    new_state, reward, done, _ = env.step(action)\n",
    "                    rewards[-1] += reward\n",
    "                    target = reward + (not done) * gamma * Q[new_state].max()\n",
    "                    error = target - Q[state][action]\n",
    "                    Q[state][action] += self.alpha() * error\n",
    "                    state = new_state\n",
    "\n",
    "                V = np.max(Q, axis=1)\n",
    "                policy = {s:a for s, a in enumerate(np.argmax(Q, axis=1))}\n",
    "                if e % (max_episodes/100) == 0:\n",
    "                    training_mean_reward = self.evaluate(env, policy)\n",
    "                    if training_mean_reward >= goal_mean_reward:\n",
    "                        pbar.update(pbar.total - e)\n",
    "                        break\n",
    "                pbar.update(1)\n",
    "        results = {\n",
    "            'Q': Q,\n",
    "            'V': V,\n",
    "            'policy': policy,\n",
    "            'training_episodes': e+1,\n",
    "            'training_mean_reward': training_mean_reward,\n",
    "        }\n",
    "        return results\n",
    "\n",
    "    def evaluate(self, env, policy, episodes=100, render=False):\n",
    "        rewards = []\n",
    "        for e in range(episodes):\n",
    "            state, is_terminal = env.reset(), False\n",
    "            rewards.append(0)\n",
    "            for t in count(start=1):\n",
    "                if render: env.render()\n",
    "                action = policy[state]\n",
    "                state, reward, is_terminal, _ = env.step(action)\n",
    "                rewards[-1] += reward\n",
    "                if is_terminal:\n",
    "                    break\n",
    "\n",
    "        if render: env.render()\n",
    "        env.close()\n",
    "        return np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSchedule():\n",
    "    def __init__(self, *args, **kwds):\n",
    "        self.params = kwds\n",
    "        for k, v in self.params.items():\n",
    "            setattr(self, k, v)\n",
    "        self.reset()\n",
    "    def __call__(self):\n",
    "        raise NotImplemented\n",
    "    def reset(self):\n",
    "        setattr(self, '_t', 0)\n",
    "    @property\n",
    "    def tick(self):\n",
    "        curr_t = self._t\n",
    "        self._t += 1\n",
    "        return curr_t\n",
    "    def __repr__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        self.params['value'] = self.value\n",
    "        params_str = ', '.join(['{}={}'.format(k, round(v, 3)) for k, v in self.params.items()])\n",
    "        return \"{}({})\".format(class_name, params_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantSchedule(BaseSchedule):\n",
    "    def __call__(self):\n",
    "        self.tick\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearlyDecayingSchedule(BaseSchedule):\n",
    "    def __call__(self):\n",
    "        self.value = max(self.min_value, self.initial_value - (1 - self.decay_rate) * self.tick)\n",
    "        return self.value\n",
    "    def reset(self):\n",
    "        super(LinearlyDecayingSchedule, self).reset()\n",
    "        self.value = self.initial_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentiallyDecayingSchedule(BaseSchedule):\n",
    "    def __call__(self):\n",
    "        self.value = max(self.min_value, self.initial_value * np.exp((self.decay_rate - 1) * self.tick))\n",
    "        return self.value\n",
    "    def reset(self):\n",
    "        super(ExponentiallyDecayingSchedule, self).reset()\n",
    "        self.value = self.initial_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5590779458944112 ConstantSchedule(value=0.559)\n",
      "1 0.5590779458944112 ConstantSchedule(value=0.559)\n",
      "2 0.5590779458944112 ConstantSchedule(value=0.559)\n",
      "3 0.5590779458944112 ConstantSchedule(value=0.559)\n",
      "4 0.5590779458944112 ConstantSchedule(value=0.559)\n",
      "0 ConstantSchedule(value=0.559)\n",
      "ConstantSchedule(value=0.559)\n",
      "0.5590779458944112 0.5590779458944112 0.5590779458944112\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = ConstantSchedule(value=uniform().rvs())\n",
    "for i in range(np.random.randint(10)):\n",
    "    print(s._t, s(), s)\n",
    "s.reset()\n",
    "print(s._t, s)\n",
    "x, y = [], []\n",
    "for i in range(1000):\n",
    "    x.append(i)\n",
    "    y.append(s())\n",
    "print(s)\n",
    "print(np.min(y), np.mean(y), np.max(y))\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=1.0)\n",
      "1 0.99 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.99)\n",
      "2 0.98 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.98)\n",
      "3 0.97 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.97)\n",
      "4 0.96 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.96)\n",
      "5 0.95 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.95)\n",
      "6 0.94 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.94)\n",
      "7 0.9299999999999999 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.93)\n",
      "8 0.9199999999999999 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.92)\n",
      "0 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=1.0)\n",
      "LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.01)\n",
      "0.01 0.05949999999999995 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99)\n",
    "for i in range(np.random.randint(10)):\n",
    "    print(s._t, s(), s)\n",
    "s.reset()\n",
    "print(s._t, s)\n",
    "x, y = [], []\n",
    "for i in range(1000):\n",
    "    x.append(i)\n",
    "    y.append(s())\n",
    "print(s)\n",
    "print(np.min(y), np.mean(y), np.max(y))\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=1.0)\n",
      "1 0.990049833749168 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.99)\n",
      "2 0.9801986733067553 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.98)\n",
      "3 0.9704455335485082 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.97)\n",
      "4 0.9607894391523232 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.961)\n",
      "5 0.951229424500714 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.951)\n",
      "6 0.9417645335842486 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.942)\n",
      "0 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=1.0)\n",
      "ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.01)\n",
      "0.01 0.10489066729883752 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99)\n",
    "for i in range(np.random.randint(10)):\n",
    "    print(s._t, s(), s)\n",
    "s.reset()\n",
    "print(s._t, s)\n",
    "x, y = [], []\n",
    "for i in range(1000):\n",
    "    x.append(i)\n",
    "    y.append(s())\n",
    "print(s)\n",
    "print(np.min(y), np.mean(y), np.max(y))\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyPolicy():\n",
    "    def __init__(self, epsilon_schedule):\n",
    "        self.epsilon_schedule = epsilon_schedule\n",
    "        self.epsilon = self.epsilon_schedule()\n",
    "    def reset(self):\n",
    "        self.epsilon_schedule.reset()\n",
    "    def select_action(self, Qs):\n",
    "        action = np.argmax(Qs) if np.random.random() > self.epsilon else np.random.randint(len(Qs))\n",
    "        self.epsilon = self.epsilon_schedule()\n",
    "        return action\n",
    "    def __repr__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        return \"{}(epsilon={}, {})\".format(class_name, self.epsilon, self.epsilon_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EpsilonGreedyPolicy(epsilon=0.9, ExponentiallyDecayingSchedule(initial_value=0.9, min_value=0.1, decay_rate=0.054, value=0.9))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = EpsilonGreedyPolicy(\n",
    "    epsilon_schedule=ExponentiallyDecayingSchedule(\n",
    "        initial_value=0.9, \n",
    "        min_value=0.1, \n",
    "        decay_rate=uniform().rvs()))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6178651223109696 0.9570024264053262 0.9996047752678702\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lot = [argus(6).rvs() for _ in range(1000)]\n",
    "print(np.min(lot), np.mean(lot), np.max(lot))\n",
    "plt.hist(lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00028304947466095687 0.06357843216464149 0.6571582874439628\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class argus_complement(rv_continuous):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.argus = argus(*args, **kwargs)\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        argus_value = self.argus.rvs(*args, **kwargs) \n",
    "        return min(max(0.0, 1 - argus_value), 1.0)\n",
    "lot = [argus_complement(5).rvs() for _ in range(1000)]\n",
    "print(np.min(lot), np.mean(lot), np.max(lot))\n",
    "plt.hist(lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052064305375783486 0.4949295933838398 0.8780826621473985\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEERJREFUeJzt3X+MZWV9x/H3R1AbqxbsDoQA2wGzGNG0i51QG6PFYlt+NKBNtWyqRUtcNdBoNE1XTaqxMaEqkpha7BoI2CiCRYQUrBJCpTZiHQRXEKkLrrCyYUe0aIOlXfj2jznbXtfZvXfn3Dt39tn3K7m55zz3Ofd898nsZ88+c36kqpAktesp0y5AkjRZBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcYdOuwCANWvW1Ozs7LTLkKQDyu233/6DqpoZ1m9VBP3s7Czz8/PTLkOSDihJvjdKP6duJKlxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcaviylhpNZvddMNU9rvtwjOnsl+1xyN6SWqcQS9JjTPoJalxQ4M+ybFJbklyT5K7k7y1a39OkpuSfKd7P7xrT5KPJNmaZEuSF036DyFJ2rtRjuh3Ae+oqucDLwbOT3IisAm4uarWATd36wCnA+u610bgkrFXLUka2dCgr6odVfX1bvknwD3A0cDZwBVdtyuAV3bLZwOfqEW3AYclOWrslUuSRrJfc/RJZoGTgK8CR1bVDlj8xwA4out2NPDgwGbbuzZJ0hSMHPRJnglcA7ytqn68r65LtNUS37cxyXyS+YWFhVHLkCTtp5GCPslTWQz5T1bVZ7vmh3dPyXTvO7v27cCxA5sfAzy053dW1eaqmququZmZoY88lCQt0yhn3QS4FLinqj488NH1wLnd8rnAdQPtf9KdffNi4NHdUzySpJU3yi0QXgK8Dvhmkju7tncBFwJXJzkPeAB4dffZjcAZwFbgMeANY61YOkhM69YL4O0XWjM06Kvqyyw97w5w6hL9Czi/Z12SpDHxylhJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxo9zUTJq6ad7gSzrQeUQvSY0z6CWpcQa9JDXOoJekxo3yKMHLkuxMctdA21VJ7uxe23Y/eSrJbJKfDnz2sUkWL0kabpSzbi4H/gb4xO6Gqvqj3ctJLgIeHeh/X1WtH1eBkqR+RnmU4K1JZpf6rHtw+GuA3x5vWZKkcek7R/9S4OGq+s5A23FJ7kjypSQv7fn9kqSe+l4wtQG4cmB9B7C2qh5J8uvA55K8oKp+vOeGSTYCGwHWrl3bswxJ0t4s+4g+yaHAHwBX7W6rqser6pFu+XbgPuCEpbavqs1VNVdVczMzM8stQ5I0RJ+pm1cA366q7bsbkswkOaRbPh5YB9zfr0RJUh+jnF55JfAV4HlJtic5r/voHH522gbgZcCWJN8A/gF4c1X9cJwFS5L2zyhn3WzYS/vrl2i7Brimf1mSpHHxylhJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuNGecLUZUl2JrlroO29Sb6f5M7udcbAZ+9MsjXJvUl+b1KFS5JGM8oR/eXAaUu0X1xV67vXjQBJTmTxEYMv6Lb5293PkJUkTcfQoK+qW4FRn/t6NvDpqnq8qr4LbAVO7lGfJKmnPnP0FyTZ0k3tHN61HQ08ONBne9f2c5JsTDKfZH5hYaFHGZKkfVlu0F8CPBdYD+wALuras0TfWuoLqmpzVc1V1dzMzMwyy5AkDbOsoK+qh6vqiap6Evg4/z89sx04dqDrMcBD/UqUJPWxrKBPctTA6quA3WfkXA+ck+TpSY4D1gH/1q9ESVIfhw7rkORK4BRgTZLtwHuAU5KsZ3FaZhvwJoCqujvJ1cC3gF3A+VX1xGRKlySNYmjQV9WGJZov3Uf/9wPv71OUJGl8vDJWkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDVu6G2KpUGzm26YdgmS9pNH9JLUuKFBn+SyJDuT3DXQ9sEk306yJcm1SQ7r2meT/DTJnd3rY5MsXpI03ChH9JcDp+3RdhPwwqr6VeDfgXcOfHZfVa3vXm8eT5mSpOUaGvRVdSvwwz3avlhVu7rV24BjJlCbJGkMxjFH/6fA5wfWj0tyR5IvJXnp3jZKsjHJfJL5hYWFMZQhSVpKr6BP8m5gF/DJrmkHsLaqTgLeDnwqybOX2raqNlfVXFXNzczM9ClDkrQPyw76JOcCvw/8cVUVQFU9XlWPdMu3A/cBJ4yjUEnS8iwr6JOcBvwFcFZVPTbQPpPkkG75eGAdcP84CpUkLc/QC6aSXAmcAqxJsh14D4tn2TwduCkJwG3dGTYvA96XZBfwBPDmqvrhkl8sSVoRQ4O+qjYs0XzpXvpeA1zTtyhJ0vh4ZawkNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEjBX2Sy5LsTHLXQNtzktyU5Dvd++Fde5J8JMnWJFuSvGhSxUuShhv1iP5y4LQ92jYBN1fVOuDmbh3gdBafFbsO2Ahc0r9MSdJyjRT0VXUrsOezX88GruiWrwBeOdD+iVp0G3BYkqPGUawkaf/1maM/sqp2AHTvR3TtRwMPDvTb3rX9jCQbk8wnmV9YWOhRhiRpXybxy9gs0VY/11C1uarmqmpuZmZmAmVIkqBf0D+8e0qme9/ZtW8Hjh3odwzwUI/9SJJ6OLTHttcD5wIXdu/XDbRfkOTTwG8Aj+6e4pF0YJjddMNU9rvtwjOnst/WjRT0Sa4ETgHWJNkOvIfFgL86yXnAA8Cru+43AmcAW4HHgDeMuWZJ0n4YKeirasNePjp1ib4FnN+nKEnS+HhlrCQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY1b9hOmkjwPuGqg6XjgL4HDgDcCu5/4/a6qunHZFUqSell20FfVvcB6gCSHAN8HrmXxiVIXV9WHxlKhJKmXcU3dnArcV1XfG9P3SZLGZFxBfw5w5cD6BUm2JLksyeFj2ockaRl6B32SpwFnAZ/pmi4BnsvitM4O4KK9bLcxyXyS+YWFhaW6SJLGYBxH9KcDX6+qhwGq6uGqeqKqngQ+Dpy81EZVtbmq5qpqbmZmZgxlSJKWMo6g38DAtE2SowY+exVw1xj2IUlapmWfdQOQ5BnA7wBvGmj+QJL1QAHb9vhMkrTCegV9VT0G/PIeba/rVZEkaay8MlaSGmfQS1LjDHpJapxBL0mN6/XLWE3H7KYbpl2CpAOIR/SS1DiP6CWtGtP63+q2C8+cyn5Xikf0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUuN5XxibZBvwEeALYVVVzSZ4DXAXMsviUqddU1Y/67kuStP/GdUT/8qpaX1Vz3fom4OaqWgfc3K1LkqZgUlM3ZwNXdMtXAK+c0H4kSUOMI+gL+GKS25Ns7NqOrKodAN37EWPYjyRpGcZx98qXVNVDSY4Abkry7VE26v5R2Aiwdu3aMZQhSVpK7yP6qnqoe98JXAucDDyc5CiA7n3nEtttrqq5qpqbmZnpW4YkaS96BX2SX0zyrN3LwO8CdwHXA+d23c4FruuzH0nS8vWdujkSuDbJ7u/6VFX9U5KvAVcnOQ94AHh1z/1IkpapV9BX1f3Ary3R/ghwap/vliSNh1fGSlLjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGjeNRgget2U03TLsESRrKI3pJatyygz7JsUluSXJPkruTvLVrf2+S7ye5s3udMb5yJUn7q8/UzS7gHVX19e65sbcnuan77OKq+lD/8iRJfS076KtqB7CjW/5JknuAo8dVmCRpPMYyR59kFjgJ+GrXdEGSLUkuS3L4OPYhSVqe3kGf5JnANcDbqurHwCXAc4H1LB7xX7SX7TYmmU8yv7Cw0LcMSdJe9Ar6JE9lMeQ/WVWfBaiqh6vqiap6Evg4cPJS21bV5qqaq6q5mZmZPmVIkvahz1k3AS4F7qmqDw+0HzXQ7VXAXcsvT5LUV5+zbl4CvA74ZpI7u7Z3ARuSrAcK2Aa8qVeFkqRe+px182UgS3x04/LLkSSNm1fGSlLjDHpJapw3NZN00JvmDQq3XXjmxPfhEb0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGtfETc2meUMiSVrtJnZEn+S0JPcm2Zpk06T2I0nat4kEfZJDgI8CpwMnsvh4wRMnsS9J0r5N6oj+ZGBrVd1fVf8NfBo4e0L7kiTtw6SC/mjgwYH17V2bJGmFTeqXsUs9NLx+pkOyEdjYrf5nknsnVMuBbA3wg2kXcQBwnIZzjEaz4uOUv+61+a+M0mlSQb8dOHZg/RjgocEOVbUZ2Dyh/TchyXxVzU27jtXOcRrOMRpNq+M0qambrwHrkhyX5GnAOcD1E9qXJGkfJnJEX1W7klwAfAE4BLisqu6exL4kSfs2sQumqupG4MZJff9Bwqmt0ThOwzlGo2lynFJVw3tJkg5Y3utGkhpn0K8Cw24XkeTtSb6VZEuSm5OMdEpVS0a9pUaSP0xSSZo7c2IUo4xTktd0P093J/nUSte4Gozwd25tkluS3NH9vTtjGnWOTVX5muKLxV9W3wccDzwN+AZw4h59Xg48o1t+C3DVtOtebWPU9XsWcCtwGzA37bpX4zgB64A7gMO79SOmXfcqHafNwFu65ROBbdOuu8/LI/rpG3q7iKq6paoe61ZvY/G6hIPJqLfU+CvgA8B/rWRxq8go4/RG4KNV9SOAqtq5wjWuBqOMUwHP7pZ/iT2uAzrQGPTTt7+3izgP+PxEK1p9ho5RkpOAY6vqH1eysFVmlJ+lE4ATkvxrktuSnLZi1a0eo4zTe4HXJtnO4tmDf7YypU1GE/ejP8ANvV3E/3VMXgvMAb810YpWn32OUZKnABcDr1+pglapUX6WDmVx+uYUFv9n+C9JXlhV/zHh2laTUcZpA3B5VV2U5DeBv+/G6cnJlzd+HtFP39DbRQAkeQXwbuCsqnp8hWpbLYaN0bOAFwL/nGQb8GLg+oPwF7Kj/CxtB66rqv+pqu8C97IY/AeTUcbpPOBqgKr6CvALLN4H54Bk0E/f0NtFdNMSf8diyB+Mc6r7HKOqerSq1lTVbFXNsvh7jLOqan465U7NKLce+RyLv9wnyRoWp3LuX9Eqp2+UcXoAOBUgyfNZDPqFFa1yjAz6KauqXcDu20XcA1xdVXcneV+Ss7puHwSeCXwmyZ1JDqr7Bo04Rge9EcfpC8AjSb4F3AL8eVU9Mp2Kp2PEcXoH8MYk3wCuBF5f3Sk4ByKvjJWkxnlEL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWrc/wLP51xP2M7J7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lot = [beta(5, 5).rvs() for _ in range(1000)]\n",
    "print(np.min(lot), np.mean(lot), np.max(lot))\n",
    "plt.hist(lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8036336443251092 0.9684999230871184 0.9999945715510861\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class beta_complement(rv_continuous):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.beta = beta(*args, **kwargs)\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        beta_value = self.beta.rvs(*args, **kwargs) \n",
    "        return min(max(0, 1 - beta_value), 1.0)\n",
    "lot = [beta_complement(1, 30).rvs() for _ in range(1000)]\n",
    "print(np.min(lot), np.mean(lot), np.max(lot))\n",
    "plt.hist(lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def c_softmax(x, sf=1, mag=2, shift=1):\n",
    "    return 1/(1 + np.exp(-x * sf)) * mag - shift\n",
    "x = np.arange(-2, 2, 0.01)\n",
    "lot = [c_softmax(i, 1, 2, 1) for i in x]\n",
    "plt.plot(x, lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def p_tanh(x, power=3, expl=0.001, mag=1, shift=0):\n",
    "    return np.tanh(np.power(x, power) * expl) * mag - shift\n",
    "x = np.arange(-15, 15, 0.01)\n",
    "lot = [p_tanh(i) for i in x]\n",
    "plt.plot(x, lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def t_power(x, power=2, expl=0.5, mag=2, shift=1):\n",
    "    return np.tanh(np.sign(x) * np.power(x, power) * expl) * mag - shift\n",
    "x = np.arange(0, 5, 0.01)\n",
    "lot = [t_power(i, power=2, expl=0.5) for i in x]\n",
    "plt.plot(x, lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfiguration:\n",
    "    def __init__(self, seeds, environments):\n",
    "        self.seeds = seeds\n",
    "        self.environments = environments\n",
    "    def data(self):\n",
    "        return [(seed, self.environments) for seed in self.seeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingEnvironment:\n",
    "    def __init__(self, \n",
    "                 env, \n",
    "                 gamma,\n",
    "                 max_episodes, \n",
    "                 goal_mean_reward,\n",
    "                 training_mean_reward_weight,\n",
    "                 training_episodes_weight,\n",
    "                 evaluation_mean_reward_weight):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.max_episodes = max_episodes\n",
    "        self.goal_mean_reward = goal_mean_reward\n",
    "        self.training_mean_reward_weight = training_mean_reward_weight\n",
    "        self.training_episodes_weight = training_episodes_weight\n",
    "        self.evaluation_mean_reward_weight = evaluation_mean_reward_weight\n",
    "    def get_environment_name(self):\n",
    "        return self.env.unwrapped.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = (\n",
    "    12,\n",
    "    34,\n",
    "    56,\n",
    "    78,\n",
    "    90,\n",
    ")\n",
    "\n",
    "environments = (\n",
    "    TrainingEnvironment(\n",
    "        env=gym.make('FrozenLake-v0'), \n",
    "        gamma=0.99,\n",
    "        max_episodes=5000,\n",
    "        goal_mean_reward=0.70,\n",
    "        training_mean_reward_weight=0.1,\n",
    "        training_episodes_weight=0.2,\n",
    "        evaluation_mean_reward_weight=0.7,\n",
    "    ),\n",
    "    #TrainingEnvironment(\n",
    "    #    env=gym.make('Taxi-v2'), \n",
    "    #    max_episodes=100000,\n",
    "    #    goal_mean_reward=800,\n",
    "    #    training_mean_reward_weight=0.03,\n",
    "    #    training_episodes_weight=0.07,\n",
    "    #    evaluation_mean_reward_weight=0.9,\n",
    "    #),\n",
    ")\n",
    "\n",
    "training_configuration = TrainingConfiguration(seeds=seeds, environments=environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamGrid():\n",
    "    def __init__(self):\n",
    "        self.grid = {}\n",
    "    def add(self, param, func, times=5):\n",
    "        if param not in self.grid:\n",
    "            self.grid[param] = []\n",
    "        self.grid[param] += [func() for _ in range(times)]\n",
    "    def data(self):\n",
    "        return self.grid\n",
    "    def __len__(self):\n",
    "        count = 0\n",
    "        for k, v in self.grid.items():\n",
    "            count += len(v)\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': [ConstantSchedule(value=0.603),\n",
       "  ConstantSchedule(value=0.723),\n",
       "  ConstantSchedule(value=0.744),\n",
       "  ConstantSchedule(value=0.341),\n",
       "  ConstantSchedule(value=0.393),\n",
       "  LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0),\n",
       "  LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0),\n",
       "  LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0),\n",
       "  LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0),\n",
       "  LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0),\n",
       "  ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0),\n",
       "  ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0),\n",
       "  ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.111, decay_rate=0.998, value=1.0),\n",
       "  ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0),\n",
       "  ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)],\n",
       " 'behavioral_strategy': [EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)),\n",
       "  EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)),\n",
       "  EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)),\n",
       "  EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)),\n",
       "  EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.999, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0))]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = ParamGrid()\n",
    "grid.add(\n",
    "    'alpha', \n",
    "    lambda: ConstantSchedule(\n",
    "        value=beta(5, 5).rvs()\n",
    "    )\n",
    ")\n",
    "grid.add(\n",
    "    'alpha', \n",
    "    lambda: LinearlyDecayingSchedule(\n",
    "        initial_value=1.0, \n",
    "        min_value=beta(10, 80).rvs(), \n",
    "        decay_rate=beta(50, 0.6).rvs()\n",
    "    )\n",
    ")\n",
    "grid.add(\n",
    "    'alpha', \n",
    "    lambda: ExponentiallyDecayingSchedule(\n",
    "        initial_value=1.0, \n",
    "        min_value=beta(10, 80).rvs(), \n",
    "        decay_rate=beta(50, 0.6).rvs()\n",
    "    )\n",
    ")\n",
    "grid.add(\n",
    "    'behavioral_strategy', \n",
    "    lambda: EpsilonGreedyPolicy(\n",
    "        epsilon_schedule=ConstantSchedule(\n",
    "            value=beta(5, 50).rvs()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "grid.add(\n",
    "    'behavioral_strategy', \n",
    "    lambda: EpsilonGreedyPolicy(\n",
    "        epsilon_schedule=LinearlyDecayingSchedule(\n",
    "            initial_value=1.0, \n",
    "            min_value=beta(1, 100).rvs(),\n",
    "            decay_rate=beta(50, 0.6).rvs()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "grid.add(\n",
    "    'behavioral_strategy', \n",
    "    lambda: EpsilonGreedyPolicy(\n",
    "        epsilon_schedule=ExponentiallyDecayingSchedule(\n",
    "            initial_value=1.0, \n",
    "            min_value=beta(1, 100).rvs(),\n",
    "            decay_rate=beta(50, 0.6).rvs()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "grid.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneToOneCV:\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return len(X)\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        for i in range(len(X)):\n",
    "            yield [np.array([i]), np.array([i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c2d8e6182042a38529ca41cfb3d5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b2628c42aa4190a8ef30bbe14b9e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b96177a558472994b027782104d487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfce627fe5d41c39285beac588396cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4b9dc555f542a6921180d04c025292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bfd007cb4540f1ad3fc7e6fa740f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b66858f4a6429c940213f145baa662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef6685c0e12414f8f75e09d87f04232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb31c7163534f64b7ca084be7c79f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dc9ba21c454221be7b1668cf5efcda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd1e8271ff84c5e852fb42d2d9e6c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73539e43025a4fdbb2f5769acab3da53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d08b99f428247a18c4543c7356876a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a473c067eb2142f48b6e23415fdab531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34619d5d55c40d793b08c6216251802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33ffe1ad2e045bf99ed4a304ed2742a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16cafe70b6f4bdf8d5e7bba3cc04516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abbbc123c4b46cbbaa16f1e17f85cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9036a4846e74f53a27488e42d975fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f845dab0664e20b2831a44f0b8bffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c683dff529401aad53a79fe728778f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e58f7659304f418903e2775df54fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa0278c4f114595a355be54be2d11d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2828154d89a489ca3fd39e212a15061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7281b0bbcc8f4c068a031f4ee288483c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db901bcf11a0461cb19a22992883c27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5545095a4054121a6f9f3307b548fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b181de43eea84dd0aea70e90e33c05d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a83d2e8dea43fda200505524b30086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c20953d00b49c88005174132f2e8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f243a5ac5a9c44279a78a49a93e4453a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c314cf5afd5441d9a1ea67c45179a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9628540027476498, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.963)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=0.168))\n",
      "Score = -0.4657152780942059. Breakdown:\n",
      "\tEvaluation mean reward = 0.54, normalized = -0.9999782399563084, weighted = -0.6999847679694159\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 901, normalized = 0.9999999958933206, weighted = 0.19999999917866412\n",
      "Total score across all environments for seed 12 = -0.4657152780942059\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16dde30998b4f3483032acb3700e96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.950472003663533, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.95)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=0.168))\n",
      "Score = 0.9939580773746546. Breakdown:\n",
      "\tEvaluation mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.6953972740596923\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 1251, normalized = 0.9994968674990963, weighted = 0.19989937349981926\n",
      "Total score across all environments for seed 90 = 0.9939580773746546\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9997594490893471, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=0.071))\n",
      "Score = 0.9110856890814126. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 1451, normalized = 0.9899345744681884, weighted = 0.1979869148936377\n",
      "Total score across all environments for seed 34 = 0.9110856890814126\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aff90919bc1443c8dbfa3bfc75db5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9876180009158833, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.988)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=0.168))\n",
      "Score = -0.4622155317827092. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 1401, normalized = 0.9945612579021861, weighted = 0.19891225158043724\n",
      "Total score across all environments for seed 78 = -0.4622155317827092\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e62d3298784738884832d750d5b9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9996391736340207, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=0.071))\n",
      "Score = 0.8057841581332867. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1701, normalized = 0.9091136535949187, weighted = 0.18182273071898375\n",
      "Total score across all environments for seed 56 = 0.8057841581332867\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44bc429364740ecbc590ee4a4ec85f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7f6b71a02d482fb0dbda74ca607bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8142700137382488, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.814)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=0.168))\n",
      "Score = 0.8871530078838054. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1501, normalized = 0.98261499588902, weighted = 0.19652299917780403\n",
      "Total score across all environments for seed 56 = 0.8871530078838054\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ef205ca7184986b40fa23cbb5570c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9998797245446736, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=0.071))\n",
      "Score = -0.5170859994475904. Breakdown:\n",
      "\tEvaluation mean reward = 0.61, normalized = -0.9967756945029475, weighted = -0.6977429861520632\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 2151, normalized = 0.40997778444664923, weighted = 0.08199555688932986\n",
      "Total score across all environments for seed 90 = -0.5170859994475904\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.972295936209412, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.972)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.47740513238097687. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 2001, normalized = 0.6173074951897601, weighted = 0.12346149903795203\n",
      "Total score across all environments for seed 78 = -0.47740513238097687\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6590f5c8664af5b94804c5ff1ac2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18da506c30e54ea6a699be353cf826d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9624131553491263, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.962)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.9356106243511527. Breakdown:\n",
      "\tEvaluation mean reward = 0.8, normalized = 0.9984202681165271, weighted = 0.6988941876815689\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 1901, normalized = 0.7378954494805599, weighted = 0.147579089896112\n",
      "Total score across all environments for seed 56 = 0.9356106243511527\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9993986227233678, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=0.071))\n",
      "Score = -0.3294464035501151. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 2401, normalized = 0.0538316597658981, weighted = 0.01076633195317962\n",
      "Total score across all environments for seed 12 = -0.3294464035501151\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.5822245511523796. Breakdown:\n",
      "\tEvaluation mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.42935008227676913\n",
      "\tTraining mean reward = 0.8, normalized = 0.9984202681165271, weighted = 0.09984202681165272\n",
      "\tTraining episodes = 2251, normalized = 0.26516221031978904, weighted = 0.05303244206395781\n",
      "Total score across all environments for seed 12 = 0.5822245511523796\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dc73d654cf40dd8b80951fbe8127a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9133260064111828, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.913)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=0.168))\n",
      "Score = 0.8313093749539672. Breakdown:\n",
      "\tEvaluation mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.6809923162787581\n",
      "\tTraining mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.09728461661125117\n",
      "\tTraining episodes = 2251, normalized = 0.26516221031978904, weighted = 0.05303244206395781"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66d93140e294f8f89873ba42e0e673d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total score across all environments for seed 34 = 0.8313093749539672\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e954dc9a1c447aa956ef462878f288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = 0.7897058130144037. Breakdown:\n",
      "\tEvaluation mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.6977429861520632\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 2451, normalized = -0.01283907889211533, weighted = -0.0025678157784230662\n",
      "Total score across all environments for seed 56 = 0.7897058130144037\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d949560028483592e3ba733015c6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92cafae7a9a4638a3fa14d9fbb286da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9309825943595155, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.931)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.9130987741877749. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 251, normalized = 1.0, weighted = 0.2\n",
      "Total score across all environments for seed 34 = 0.9130987741877749\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d94f58c73744c3d89a622cb7a822180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9185558675613521, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.919)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.33492470714101163. Breakdown:\n",
      "\tEvaluation mean reward = 0.66, normalized = -0.8913734677347183, weighted = -0.6239614274143027\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 1251, normalized = 0.9994968674990963, weighted = 0.19989937349981926\n",
      "Total score across all environments for seed 56 = -0.33492470714101163\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257354b17071495480218abe2a647eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.7783863334298268. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 3001, normalized = -0.5634346932729546, weighted = -0.11268693865459092\n",
      "Total score across all environments for seed 90 = -0.7783863334298268\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b61af858f3849e79fd7917259534cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9389169006710141, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.939)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = 0.8857766829397844. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 1801, normalized = 0.8364230644235897, weighted = 0.16728461288471796\n",
      "Total score across all environments for seed 34 = 0.8857766829397844\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83fccf5754749fa85e7e4e73649ed77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.7250694842246463. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 2901, normalized = -0.4881223821792423, weighted = -0.09762447643584847\n",
      "Total score across all environments for seed 12 = -0.7250694842246463\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.48753873785150315. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 3301, normalized = -0.736630011741042, weighted = -0.14732600234820842\n",
      "Total score across all environments for seed 90 = -0.48753873785150315\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee75eab337d452f99b0171ab63b9748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30ed8e67364443683c82a80a2183841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.979638966890338, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.98)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = 0.497776687747657. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.8, normalized = 0.9984202681165271, weighted = 0.09984202681165272\n",
      "\tTraining episodes = 1851, normalized = 0.7902411303009154, weighted = 0.1580482260601831\n",
      "Total score across all environments for seed 78 = 0.497776687747657\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9185558675613521, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.919)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = 0.500991857670545. Breakdown:\n",
      "\tEvaluation mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.42935008227676913\n",
      "\tTraining mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.09934246772281319\n",
      "\tTraining episodes = 2551, normalized = -0.13850346164518668, weighted = -0.027700692329037338\n",
      "Total score across all environments for seed 12 = 0.500991857670545\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6734769d2fee4d0e841ae7178fb10e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a837bc5b6c49e987e430cf9f289b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9995188981786942, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=0.071))\n",
      "Score = 0.46389490567386904. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.81, normalized = 0.999226343498715, weighted = 0.0999226343498715\n",
      "\tTraining episodes = 4051, normalized = -0.9451345482381608, weighted = -0.18902690964763216\n",
      "Total score across all environments for seed 78 = 0.46389490567386904\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f0a27e6ca047719ff8cc6473818118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9232512448220334, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=0.923)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=0.098))\n",
      "Score = 0.9964044159672062. Breakdown:\n",
      "\tEvaluation mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.6977429861520632\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 301, normalized = 1.0, weighted = 0.2\n",
      "Total score across all environments for seed 56 = 0.9964044159672062\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f1b9d392e545e98683cd14c25c7681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9898356246362454, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.99)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.2726850300498239. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 2201, normalized = 0.3376385272673543, weighted = 0.06752770545347087\n",
      "Total score across all environments for seed 12 = -0.2726850300498239\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b613a5d5cd3b493081b2d6cefbc68f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9949048319493907, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.995)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.4008818747610981. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2151, normalized = 0.40997778444664923, weighted = 0.08199555688932986\n",
      "Total score across all environments for seed 78 = 0.4008818747610981\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.6040203870158334. Breakdown:\n",
      "\tEvaluation mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.6953972740596923\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 3951, normalized = -0.9295376484231119, weighted = -0.1859075296846224\n",
      "Total score across all environments for seed 56 = 0.6040203870158334\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3cc35937084f158749b7e0c4a68da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee80a3fd737a431f8f1607f54a49db88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8574727682323662, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.857)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.6318620984448858. Breakdown:\n",
      "\tEvaluation mean reward = 0.63, normalized = -0.9866142981514303, weighted = -0.6906300087060012\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 2451, normalized = -0.01283907889211533, weighted = -0.0025678157784230662\n",
      "Total score across all environments for seed 90 = -0.6318620984448858\n",
      "---------------------------------------------\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9673419250195006, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.967)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.8572648745483469. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 4351, normalized = -0.977751880315016, weighted = -0.1955503760630032Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9976016014006885, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=0.998)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=0.098))\n",
      "Score = -0.4340615480581679. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 851, normalized = 0.9999999998099298, weighted = 0.19999999996198597\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0)}\n",
      "\n",
      "Total score across all environments for seed 34 = -0.8572648745483469\n",
      "Total score across all environments for seed 12 = -0.4340615480581679\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae64f7964a2a41fea5431278a10489ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1d4a76e98144b79d9afee89f0a1e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3724f90493de4feab137e6ce3e194dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.04, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.03, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74a32382bb347e7ac7714f55af84abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7273ab1c26414ab2957c8a90f20312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc60e1e71ba4074a8a165fee811093e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9949048319493907, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.995)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.5980350036213552. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 2401, normalized = 0.0538316597658981, weighted = 0.01076633195317962\n",
      "Total score across all environments for seed 90 = 0.5980350036213552\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.8152018123510852. Breakdown:\n",
      "\tEvaluation mean reward = 0.63, normalized = -0.9866142981514303, weighted = -0.6906300087060012\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 3951, normalized = -0.9295376484231119, weighted = -0.1859075296846224\n",
      "Total score across all environments for seed 12 = -0.8152018123510852\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198132d2f8f243a69ba0cd872a896192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d24febf395477dbf83f3d1a1e0413c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa33a1d76a7409683ef02a41eba7e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34714574bcf94b8b92f8e96d6e41d268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7339e810385b4dd5afc9a89504d20aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6799c165e5d04079810b1b5c4cb926a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9bb68a9a9b4d45b6e94e0d17ecefdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9856096084041313, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=0.986)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=0.098))\n",
      "Score = 0.5385477709947993. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 1001, normalized = 0.9999995315191756, weighted = 0.19999990630383513Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.744)}\n",
      "\n",
      "Total score across all environments for seed 78 = 0.5385477709947993\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9b2df95cf34ebdad719b34e0b44d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5172e52f0a054f5fbe12261f506b8e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d326dddcfb84e31ba275cba858638a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c086bf9db067465292eac184a6b9e9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9880080070034427, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=0.988)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=0.098))\n",
      "Score = 0.9002437887446174. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 1651, normalized = 0.9357250727842126, weighted = 0.18714501455684251\n",
      "\n",
      "Total score across all environments for seed 34 = 0.9002437887446174\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.744)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9928048042020656, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=0.993)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=0.098))\n",
      "Score = 0.04867214706863697. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.09728461661125117\n",
      "\tTraining episodes = 1601, normalized = 0.9563698266660432, weighted = 0.19127396533320865\n",
      "Total score across all environments for seed 90 = 0.04867214706863697\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.744)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999985636957. Breakdown:\n",
      "\tEvaluation mean reward = 0.41, normalized = -0.9999999979819588, weighted = -0.6999999985873712\n",
      "\tTraining mean reward = 0.38, normalized = -0.999999999763245, weighted = -0.09999999997632451\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999985636957\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.744)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9121530652930798, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.912)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.8251520629712299. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 3501, normalized = -0.8171878224294309, weighted = -0.1634375644858862\n",
      "Total score across all environments for seed 56 = -0.8251520629712299\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b715465c1442b6bc2fe6cf654602bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a4cf3619494e3c827acd4c12f50fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86fb2e9da6ac4d58a3821782732ace58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177f7ae0a0154941b35bf09cfbb3bc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.06, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.08, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0722fded8c6e4148aca9d0dca9eee8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.6992769056671188. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 2801, normalized = -0.4024522490617721, weighted = -0.08049044981235443\n",
      "Total score across all environments for seed 78 = 0.6992769056671188\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e805081896f149d4ad2006d5d3bfb709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9671008414870099, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.967)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=0.06))\n",
      "Score = 0.8797827204649604. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2051, normalized = 0.5507641438150594, weighted = 0.1101528287630119\n",
      "Total score across all environments for seed 56 = 0.8797827204649604\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390614ca32e74a64a9f1129f0b57c3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662345e3e66241d4b077e6c419112388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.7656797816031096. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 4601, normalized = -0.9924796287926463, weighted = -0.19849592575852926\n",
      "Total score across all environments for seed 90 = -0.7656797816031096\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc9bb9bd3de4024957b8880f2e1c8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9098263111295232, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.91)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = 0.823961427414303. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 651, normalized = 1.0, weighted = 0.2\n",
      "Total score across all environments for seed 34 = 0.823961427414303\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9905652252485234, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.991)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.5777378700161397. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2301, normalized = 0.19329760523802686, weighted = 0.03865952104760537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44a2caf3a1a439faf4ccd37fa9bdee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score across all environments for seed 78 = -0.5777378700161397\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.980260504892206, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.98)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=0.06))\n",
      "Score = -0.7276695778008191. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 2551, normalized = -0.13850346164518668, weighted = -0.027700692329037338\n",
      "Total score across all environments for seed 90 = -0.7276695778008191\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c34f4a13ce4ae5936087512a1543e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9915046831234728, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.992)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.07889099499054586. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2151, normalized = 0.40997778444664923, weighted = 0.08199555688932986\n",
      "Total score across all environments for seed 90 = -0.07889099499054586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39e10e8c3c14dc5bfc7dc29fce1d0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355dcc2507a74274ab628487c4d85a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.993420168297402, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.993)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=0.06))\n",
      "Score = -0.7467484866747448. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 3001, normalized = -0.5634346932729546, weighted = -0.11268693865459092\n",
      "Total score across all environments for seed 78 = -0.7467484866747448\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9539411780818139, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.954)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=0.06))\n",
      "Score = 0.5208823777718653. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 3201, normalized = -0.6867427016949178, weighted = -0.13734854033898355\n",
      "Total score across all environments for seed 34 = 0.5208823777718653\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9276218512714218, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.928)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.6950562650828433. Breakdown:\n",
      "\tEvaluation mean reward = 0.66, normalized = -0.8913734677347183, weighted = -0.6239614274143027\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 2751, normalized = -0.35547418834270317, weighted = -0.07109483766854063\n",
      "Total score across all environments for seed 56 = -0.6950562650828433\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741e7c34a1a5478da34982de0e60f8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a939dfa0ec9d48358974d1e7e5a91be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647680c06b124d59b577021fa44214d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ef6b3846ff4c419815e79863538f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e110e46c23a14c6d95183d5d3a9d511a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.993420168297402, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.993)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.7843741244737557. Breakdown:\n",
      "\tEvaluation mean reward = 0.56, normalized = -0.9999092042625951, weighted = -0.6999364429838165\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 3501, normalized = -0.8171878224294309, weighted = -0.1634375644858862\n",
      "Total score across all environments for seed 78 = -0.7843741244737557\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e41f6de9244ca29b04fd8675b088d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5b2d7cc7254aa6aefb03dabcf2af1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9671008414870099, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.967)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.32766165497319394. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 3551, normalized = -0.8338755154665909, weighted = -0.1667751030933182\n",
      "Total score across all environments for seed 90 = -0.32766165497319394\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef524d8c7894c0994664144b0707073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = 0.15055910250693386. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 2851, normalized = -0.4466366618444364, weighted = -0.08932733236888729\n",
      "Total score across all environments for seed 78 = 0.15055910250693386\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = -0.49883073457162597. Breakdown:\n",
      "\tEvaluation mean reward = 0.61, normalized = -0.9967756945029475, weighted = -0.6977429861520632\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1401, normalized = 0.9945612579021861, weighted = 0.19891225158043724\n",
      "Total score across all environments for seed 78 = -0.49883073457162597\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5297cd1b583c4add9efcb018fef5db69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e21990464b749aa8719e2ea98cb50c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.980260504892206, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.98)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=0.06))\n",
      "Score = -0.8916036805577638. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 4151, normalized = -0.9581739754299106, weighted = -0.19163479508598213\n",
      "Total score across all environments for seed 12 = -0.8916036805577638\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae26b56c99c42fe990a8e078ddcbc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bb2636d99947469aadd68e78d2d1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9546299190640855, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=0.955)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = 0.9320013463195634. Breakdown:\n",
      "\tEvaluation mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.6977429861520632\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 1151, normalized = 0.999944347354772, weighted = 0.1999888694709544\n",
      "Total score across all environments for seed 34 = 0.9320013463195634\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9257080054952995, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.926)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.8877149908164212. Breakdown:\n",
      "\tEvaluation mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.6953972740596923\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 1851, normalized = 0.7902411303009154, weighted = 0.1580482260601831\n",
      "Total score across all environments for seed 56 = 0.8877149908164212\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.7152140210653148, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.715)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.9815815434895048. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.09967756945029477\n",
      "\tTraining episodes = 1601, normalized = 0.9563698266660432, weighted = 0.19127396533320865\n",
      "Total score across all environments for seed 78 = 0.9815815434895048\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e40e986d7954980917e100fcf6f7d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.900944007327066, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.901)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.9164789849487043. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 1451, normalized = 0.9899345744681884, weighted = 0.1979869148936377\n",
      "Total score across all environments for seed 90 = 0.9164789849487043\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9342016829740198, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.934)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = 0.48900198515424137. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 4401, normalized = -0.9814758414980008, weighted = -0.19629516829960017"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3a06621d3540ada7741a3eb93e12aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total score across all environments for seed 34 = 0.48900198515424137\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d766ab2c6643aabfbf3bcfe868b732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0808eda25bb64029ae6d342bb39e1391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.996215354221057, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.996)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.2777120432886926. Breakdown:\n",
      "\tEvaluation mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.42935008227676913\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 3951, normalized = -0.9295376484231119, weighted = -0.1859075296846224\n",
      "Total score across all environments for seed 12 = 0.2777120432886926\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b49c843a36e494188fdad3058682e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.5552142792831369. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 3101, normalized = -0.6293209850318515, weighted = -0.1258641970063703\n",
      "Total score across all environments for seed 90 = -0.5552142792831369\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c40d29167f54b81a8f6fea64737d5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = -0.7368101149414107. Breakdown:\n",
      "\tEvaluation mean reward = 0.54, normalized = -0.9999782399563084, weighted = -0.6999847679694159\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 2751, normalized = -0.35547418834270317, weighted = -0.07109483766854063\n",
      "Total score across all environments for seed 12 = -0.7368101149414107\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebe77ba9025497d885a34efefd13c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f727c59f2e54ab69dd70bbaca6056af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9483187405383926, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=0.948)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = 0.6725085390352913. Breakdown:\n",
      "\tEvaluation mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.42935008227676913\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 1701, normalized = 0.9091136535949187, weighted = 0.18182273071898375\n",
      "Total score across all environments for seed 12 = 0.6725085390352913\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9747824477447575, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.975)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = -0.5097414759226098. Breakdown:\n",
      "\tEvaluation mean reward = 0.6, normalized = -0.9984202681165271, weighted = -0.6988941876815689\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2051, normalized = 0.5507641438150594, weighted = 0.1101528287630119\n",
      "Total score across all environments for seed 90 = -0.5097414759226098\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7f96ca5c054540adc63041e47bec36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4bd8e40a29456b88f8fe86d3484b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9752360018317665, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.975)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.3296526498249479. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2401, normalized = 0.0538316597658981, weighted = 0.01076633195317962\n",
      "Total score across all environments for seed 12 = 0.3296526498249479\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.950472003663533, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.95)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.8504529976663158. Breakdown:\n",
      "\tEvaluation mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.6977429861520632\n",
      "\tTraining mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.09967756945029477\n",
      "\tTraining episodes = 2251, normalized = 0.26516221031978904, weighted = 0.05303244206395781\n",
      "Total score across all environments for seed 34 = 0.8504529976663158\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9473613463792159, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.947)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999688854481062. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.38, normalized = -0.999999999763245, weighted = -0.09999999997632451\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999688854481062\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fe0311c7fa4a1d8d603cb5c8ee2a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56e3e8c7205476e82773c115a461a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87daf2459f824845b6a9a3a94f5631dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9923669914836164, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.992)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = 0.8362151385443173. Breakdown:\n",
      "\tEvaluation mean reward = 0.8, normalized = 0.9984202681165271, weighted = 0.6988941876815689\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 2301, normalized = 0.19329760523802686, weighted = 0.03865952104760537\n",
      "Total score across all environments for seed 56 = 0.8362151385443173\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe79ab2e8e74137aa47af3d5bce595b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8874568572684327, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=0.887)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = 0.00859430572055813. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 1651, normalized = 0.9357250727842126, weighted = 0.18714501455684251\n",
      "Total score across all environments for seed 90 = 0.00859430572055813\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc37677f014547c4bb1a1153591f7a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9546299190640855, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=0.955)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = -0.5651558290056024. Breakdown:\n",
      "\tEvaluation mean reward = 0.66, normalized = -0.8913734677347183, weighted = -0.6239614274143027\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 2351, normalized = 0.12268053856077255, weighted = 0.02453610771215451\n",
      "Total score across all environments for seed 56 = -0.5651558290056024\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0928bb2627eb40eb89995c176dcd55b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9992783472680413, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.7238801336534844. Breakdown:\n",
      "\tEvaluation mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.42935008227676913\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 1051, normalized = 0.9999970436797587, weighted = 0.19999940873595176\n",
      "Total score across all environments for seed 12 = 0.7238801336534844\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2f4a5be009480e92773b0c29c930ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9858812711646208, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.986)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.9999997291668844. Breakdown:\n",
      "\tEvaluation mean reward = 0.48, normalized = -0.9999997004961856, weighted = -0.6999997903473298\n",
      "\tTraining mean reward = 0.49, normalized = -0.9999993881955461, weighted = -0.09999993881955462\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "\n",
      "\n",
      "Total score across all environments for seed 34 = -0.9999997291668844\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9868214553045994, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=0.987)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = -0.4621149963175191. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.09728461661125117\n",
      "\tTraining episodes = 1951, normalized = 0.6799883056546103, weighted = 0.13599766113092207\n",
      "Total score across all environments for seed 78 = -0.4621149963175191\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.341)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67740e518dd42549992d662e0769fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeeb1f4cc6f9435c91e1f127ade11b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6794de721640a28351bd3554b0587c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6a92734c064f45b3e0555e29bb09e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51484dd3ef504eb3991e0fdd56810794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7e9fd5b0b446b6be091e426d2c5d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9990524927507252, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.3906300087543639. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.39, normalized = -0.9999999995163743, weighted = -0.09999999995163744\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = 0.3906300087543639\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.341)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f29f0ed58c0410c858b0f6be5ee928b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9992783472680413, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.7872658100904776. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 1101, normalized = 0.9999856921115104, weighted = 0.1999971384223021\n",
      "Total score across all environments for seed 78 = 0.7872658100904776\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.341)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e1badb13184fae963931f245c7f16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.2670028080521689, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.267)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.8429345761199813. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 1601, normalized = 0.9563698266660432, weighted = 0.19127396533320865\n",
      "Total score across all environments for seed 78 = 0.8429345761199813\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ConstantSchedule(value=0.603)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4e3e0309f0422f8899e40cec01ee8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9998797245446736, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.9547208291936955. Breakdown:\n",
      "\tEvaluation mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.6617144984853439\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 1551, normalized = 0.9717245044660427, weighted = 0.19434490089320855\n",
      "Total score across all environments for seed 34 = 0.9547208291936955\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ConstantSchedule(value=0.603)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf4f9f4ecc847e693e155047d016d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ConstantSchedule(value=0.603)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ConstantSchedule(value=0.603)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a029a70cddf04b80889eb8f71969c0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9995188981786942, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.4451332947793161. Breakdown:\n",
      "\tEvaluation mean reward = 0.61, normalized = -0.9967756945029475, weighted = -0.6977429861520632\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 1601, normalized = 0.9563698266660432, weighted = 0.19127396533320865\n",
      "Total score across all environments for seed 90 = -0.4451332947793161\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ConstantSchedule(value=0.603)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6f735b8d1e4a7b802bccfe56b57172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7fec996d7b4b42a5b7c414aed1c80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8167507020130422, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.817)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.48497134134491254. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 1951, normalized = 0.6799883056546103, weighted = 0.13599766113092207\n",
      "Total score across all environments for seed 12 = -0.48497134134491254\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f19839bfe049548f293accdfda1ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b724976f77f246e3830c649956b303de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b22ab49f22d42d0a6255b21e9b232f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9429479294766345, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.943)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.6838881012421132. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 2951, normalized = -0.5270166863951559, weighted = -0.10540333727903117\n",
      "Total score across all environments for seed 34 = 0.6838881012421132\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42334f9b37a948d5a6c698d299500aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9986769699914091, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.8621185635085516. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 2051, normalized = 0.5507641438150594, weighted = 0.1101528287630119\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9987972454467355, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.8337918256276098. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.09967756945029477\n",
      "\tTraining episodes = 2051, normalized = 0.5507641438150594, weighted = 0.1101528287630119Total score across all environments for seed 56 = 0.8621185635085516\n",
      "\n",
      "---------------------------------------------\n",
      "Total score across all environments for seed 34 = 0.8337918256276098\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.61752765193846. Breakdown:\n",
      "\tEvaluation mean reward = 0.67, normalized = -0.7899988299594689, weighted = -0.5529991809716281\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 3101, normalized = -0.6293209850318515, weighted = -0.1258641970063703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af840e7591cc4d4e986d6824639262ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score across all environments for seed 90 = -0.61752765193846\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f0388d596843cc83606afa62e52c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8778338013420282, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.878)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.5380895936626098. Breakdown:\n",
      "\tEvaluation mean reward = 0.66, normalized = -0.8913734677347183, weighted = -0.6239614274143027\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 2351, normalized = 0.12268053856077255, weighted = 0.02453610771215451\n",
      "Total score across all environments for seed 56 = -0.5380895936626098\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9987972454467355, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ConstantSchedule(value=0.603))\n",
      "Score = -0.13481944045733907. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 901, normalized = 0.9999999958933206, weighted = 0.19999999917866412\n",
      "Total score across all environments for seed 12 = -0.13481944045733907\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0edeb327842445ba9857fa9d1b7181d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0047cf70d1430590c206142fc34fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9990377963573884, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.2973177572168617. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2251, normalized = 0.26516221031978904, weighted = 0.05303244206395781\n",
      "Total score across all environments for seed 12 = -0.2973177572168617\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f36bbb315c40f193366ea4961b56d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9995188981786942, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=ConstantSchedule(value=0.603))\n",
      "Score = 0.8143349070111581. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 751, normalized = 0.9999999999999498, weighted = 0.19999999999998996\n",
      "Total score across all environments for seed 34 = 0.8143349070111581\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb07b98c7b834ff18d80543d6f2f7f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f2adac4c734c9da59848b882f60121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.6292508551642859. Breakdown:\n",
      "\tEvaluation mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.6617144984853439\n",
      "\tTraining mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.09934246772281319\n",
      "\tTraining episodes = 3151, normalized = -0.6590305552193557, weighted = -0.13180611104387116\n",
      "Total score across all environments for seed 78 = 0.6292508551642859\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e0db8178af413290aa78f53eeca6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9997594490893471, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=ConstantSchedule(value=0.603))\n",
      "Score = 0.9567330000983009. Breakdown:\n",
      "\tEvaluation mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.6953972740596923\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 801, normalized = 0.9999999999953508, weighted = 0.19999999999907017\n",
      "Total score across all environments for seed 56 = 0.9567330000983009\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9993986227233678, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ConstantSchedule(value=0.603))\n",
      "Score = 0.5012221501883594. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 951, normalized = 0.9999999463649991, weighted = 0.19999998927299983\n",
      "Total score across all environments for seed 78 = 0.5012221501883594\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bae3dc4efad4ef3a0a75fd66cc5c7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3be7314aa84a5bb8babb3be59ae98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9977147663487975, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.998)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.5151953181675657. Breakdown:\n",
      "\tEvaluation mean reward = 0.53, normalized = -0.9999893474929373, weighted = -0.6999925432450561\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 2001, normalized = 0.6173074951897601, weighted = 0.12346149903795203\n",
      "Total score across all environments for seed 90 = -0.5151953181675657\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.993386272680481, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.993)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.9797673554794631. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 751, normalized = 0.9999999999999498, weighted = 0.19999999999998996\n",
      "Total score across all environments for seed 56 = 0.9797673554794631\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d7670f1ef44d8cb9581ed861302fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8215783cd228482d84f8bb4e09142ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9991580718127149, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.32176635945606485. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.09728461661125117\n",
      "\tTraining episodes = 2501, normalized = -0.07702346015503725, weighted = -0.015404692031007451\n",
      "Total score across all environments for seed 78 = 0.32176635945606485\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4720cff17c8d4645b34187dae18b17e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.7760286357937183, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.776)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.5162723307387312. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 3101, normalized = -0.6293209850318515, weighted = -0.1258641970063703\n",
      "Total score across all environments for seed 90 = 0.5162723307387312\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd3dd6279fb4bf0938a7e1f7b3d0a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9752226010222359, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.975)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.46171459218150857. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1001, normalized = 0.9999995315191756, weighted = 0.19999990630383513\n",
      "Total score across all environments for seed 56 = -0.46171459218150857\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac6a57818004b7c96c38fac62fe0965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9943284060533764, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.994)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.8818201526316455. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 1501, normalized = 0.98261499588902, weighted = 0.19652299917780403\n",
      "Total score across all environments for seed 34 = 0.8818201526316455\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8778338013420282, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.878)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.7712874297625112. Breakdown:\n",
      "\tEvaluation mean reward = 0.66, normalized = -0.8913734677347183, weighted = -0.6239614274143027\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 3301, normalized = -0.736630011741042, weighted = -0.14732600234820842\n",
      "Total score across all environments for seed 34 = -0.7712874297625112\n",
      "---------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeab908d016043dfa1b5e3beec1c6d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9752226010222359, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.975)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.46171459218150857. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1001, normalized = 0.9999995315191756, weighted = 0.19999990630383513\n",
      "Total score across all environments for seed 56 = -0.46171459218150857\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.972295936209412, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.972)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999908. Breakdown:\n",
      "\tEvaluation mean reward = 0.05, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.27, normalized = -0.9999999999999084, weighted = -0.09999999999999085\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999908\n",
      "---------------------------------------------\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9990377963573884, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.607274321211307. Breakdown:\n",
      "\tEvaluation mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.6977429861520632\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 3351, normalized = -0.759021954901473, weighted = -0.1518043909802946\n",
      "Total score across all environments for seed 56 = 0.607274321211307\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9873107148941298, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.987)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.01, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9752226010222359, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.975)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.1481848838349697. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.09934246772281319\n",
      "\tTraining episodes = 1701, normalized = 0.9091136535949187, weighted = 0.18182273071898375\n",
      "Total score across all environments for seed 12 = -0.1481848838349697\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.5464303826041197. Breakdown:\n",
      "\tEvaluation mean reward = 0.67, normalized = -0.7899988299594689, weighted = -0.5529991809716281\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 2551, normalized = -0.13850346164518668, weighted = -0.027700692329037338\n",
      "Total score across all environments for seed 78 = -0.5464303826041197\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9943284060533764, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.994)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.4713485465475253. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 1801, normalized = 0.8364230644235897, weighted = 0.16728461288471796\n",
      "Total score across all environments for seed 90 = -0.4713485465475253\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9981058832714378, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.998)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.5523573530877045. Breakdown:\n",
      "\tEvaluation mean reward = 0.56, normalized = -0.9999092042625951, weighted = -0.6999364429838165\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1901, normalized = 0.7378954494805599, weighted = 0.147579089896112\n",
      "Total score across all environments for seed 78 = -0.5523573530877045\n",
      "---------------------------------------------\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8948396355581706, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.895)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.8471861086764909. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.8, normalized = 0.9984202681165271, weighted = 0.09984202681165272\n",
      "\tTraining episodes = 1551, normalized = 0.9717245044660427, weighted = 0.19434490089320855\n",
      "Total score across all environments for seed 78 = 0.8471861086764909\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9476564200714348, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.948)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.20654611551600144. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.09934246772281319\n",
      "\tTraining episodes = 2001, normalized = 0.6173074951897601, weighted = 0.12346149903795203\n",
      "Total score across all environments for seed 12 = -0.20654611551600144\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9175747512621146, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.918)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.6221423414349387. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2601, normalized = -0.19713862972771112, weighted = -0.039427725945542225\n",
      "Total score across all environments for seed 34 = -0.6221423414349387\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9822385382330083, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.982)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.7276371353128539. Breakdown:\n",
      "\tEvaluation mean reward = 0.56, normalized = -0.9999092042625951, weighted = -0.6999364429838165\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining episodes = 2551, normalized = -0.13850346164518668, weighted = -0.027700692329037338\n",
      "Total score across all environments for seed 78 = -0.7276371353128539\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9175747512621146, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.918)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.6221423414349387. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2601, normalized = -0.19713862972771112, weighted = -0.039427725945542225\n",
      "Total score across all environments for seed 34 = -0.6221423414349387\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.3275633181588307. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 3851, normalized = -0.9110376296188566, weighted = -0.18220752592377132\n",
      "Total score across all environments for seed 78 = -0.3275633181588307\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9857654119503506, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.986)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.2702482508612507. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 3051, normalized = -0.5974958137944986, weighted = -0.11949916275889971\n",
      "Total score across all environments for seed 90 = -0.2702482508612507\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9990524927507252, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.15082164403942397. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.82, normalized = 0.9996211881123498, weighted = 0.09996211881123498\n",
      "\tTraining episodes = 4051, normalized = -0.9451345482381608, weighted = -0.18902690964763216\n",
      "Total score across all environments for seed 12 = 0.15082164403942397\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9991580718127149, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ConstantSchedule(value=0.603))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.08, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.08, normalized = -1.0, weighted = -0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9613407090399768, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.961)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.4627485378883773. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.09728461661125117\n",
      "\tTraining episodes = 4001, normalized = -0.9376762984725178, weighted = -0.18753525969450358\n",
      "Total score across all environments for seed 90 = 0.4627485378883773\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.40492779780833704. Breakdown:\n",
      "\tEvaluation mean reward = 0.81, normalized = 0.999226343498715, weighted = 0.6994584404491004\n",
      "\tTraining mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.09453064264076338\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = 0.40492779780833704\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<__main__.OneToOneCV object at 0x7f904f7fccf8>,\n",
       "          error_score='raise', estimator=Qlearning(), fit_params=None,\n",
       "          iid=False, n_iter=30, n_jobs=-1,\n",
       "          param_distributions={'alpha': [ConstantSchedule(value=0.603), ConstantSchedule(value=0.723), ConstantSchedule(value=0.744), ConstantSchedule(value=0.341), ConstantSchedule(value=0.393), LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0), LinearlyDecayingSchedule(...0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0))]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=False,\n",
       "          return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = Qlearning()\n",
    "rsearch = RandomizedSearchCV(estimator=agent, \n",
    "                             param_distributions=grid.data(), \n",
    "                             n_iter=len(grid),\n",
    "                             cv=OneToOneCV(), \n",
    "                             refit=False,\n",
    "                             iid=False,\n",
    "                             return_train_score=False,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=0)\n",
    "rsearch.fit(training_configuration.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.7931762333491787\n",
      "alpha ConstantSchedule(value=0.723)\n",
      "behavioral_strategy EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0))\n"
     ]
    }
   ],
   "source": [
    "print('best score', rsearch.best_score_)\n",
    "print('alpha', rsearch.best_params_['alpha'])\n",
    "print('behavioral_strategy', rsearch.best_params_['behavioral_strategy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), alpha=ConstantSchedule(value=0.723))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.set_params(**rsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f33423f78114a2e889a941032c78fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'FrozenLakeEnv': {'Q': array([[8.83171143e-01, 8.48361547e-01, 8.63116620e-01, 8.34891007e-01],\n",
       "         [2.19993193e-01, 8.30016277e-01, 8.43245574e-01, 8.32565747e-01],\n",
       "         [8.72758359e-01, 8.64602813e-01, 8.17897299e-01, 8.60120241e-01],\n",
       "         [8.15647246e-01, 6.04349267e-01, 2.17381815e-01, 8.17316040e-01],\n",
       "         [8.81167715e-01, 1.98094579e-01, 2.48495198e-01, 6.77279527e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [8.72912085e-01, 8.34838009e-01, 6.94591618e-02, 3.46298619e-04],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [8.96017829e-01, 2.54315351e-01, 8.30648582e-01, 9.12210522e-01],\n",
       "         [8.65292166e-01, 9.51337417e-01, 7.51824650e-01, 8.48523853e-01],\n",
       "         [9.49771466e-01, 2.56589306e-01, 8.21890496e-01, 2.21240698e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [8.55617926e-01, 9.65224347e-01, 9.77256629e-01, 2.46943751e-01],\n",
       "         [9.32548702e-01, 9.78161953e-01, 9.45735787e-01, 9.65264187e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'V': array([0.88317114, 0.84324557, 0.87275836, 0.81731604, 0.88116771,\n",
       "         0.        , 0.87291208, 0.        , 0.91221052, 0.95133742,\n",
       "         0.94977147, 0.        , 0.        , 0.97725663, 0.97816195,\n",
       "         0.        ]),\n",
       "  'policy': {0: 0,\n",
       "   1: 2,\n",
       "   2: 0,\n",
       "   3: 3,\n",
       "   4: 0,\n",
       "   5: 0,\n",
       "   6: 0,\n",
       "   7: 0,\n",
       "   8: 3,\n",
       "   9: 1,\n",
       "   10: 0,\n",
       "   11: 0,\n",
       "   12: 0,\n",
       "   13: 2,\n",
       "   14: 1,\n",
       "   15: 0},\n",
       "  'training_episodes': 1551,\n",
       "  'training_mean_reward': 0.73}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "for environment in environments:\n",
    "    results[environment.get_environment_name()] = agent.train(environment.env, \n",
    "                                                              environment.gamma,\n",
    "                                                              environment.max_episodes, \n",
    "                                                              environment.goal_mean_reward)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for environment in environments:\n",
    "    agent.demo(environment, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

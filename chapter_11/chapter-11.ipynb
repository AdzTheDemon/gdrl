{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~DAGGER, GPS, PILCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 21 02:16:46 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 396.54                 Driver Version: 396.54                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN X (Pascal)    Off  | 00000000:0B:00.0 Off |                  N/A |\r\n",
      "| 36%   60C    P2    61W / 250W |   1060MiB / 12196MiB |     24%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  TITAN X (Pascal)    Off  | 00000000:41:00.0  On |                  N/A |\r\n",
      "| 29%   49C    P5    21W / 250W |   2471MiB / 12188MiB |     17%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle, count\n",
    "from textwrap import wrap\n",
    "\n",
    "import subprocess\n",
    "import os.path\n",
    "import tempfile\n",
    "import random\n",
    "import base64\n",
    "import pprint\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import gym\n",
    "import io\n",
    "\n",
    "from gym import wrappers\n",
    "from subprocess import check_output\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_monitored_env(env_name, monitor_mode, seed):\n",
    "    mdir = tempfile.mkdtemp()\n",
    "    env = gym.make(env_name)\n",
    "    env = wrappers.Monitor(env, mdir, force=True, mode=monitor_mode)\n",
    "    env.seed(seed)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, log_scale=False):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    lines = [\"-\",\"--\",\":\",\"-.\"]\n",
    "    linecycler = cycle(lines)\n",
    "    for experiment, experiment_name, env in results:\n",
    "        label = '\\n'.join(wrap(experiment_name.replace('_', ', '), 50))\n",
    "        plt.plot(experiment, next(linecycler), label=label)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    if log_scale: plt.xscale('log')\n",
    "    plt.ylabel('Rewards')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_html(env_videos, title, max_n_videos=3):\n",
    "    videos = np.array(env_videos)\n",
    "    n_videos = min(max_n_videos, len(videos))\n",
    "    idxs = np.linspace(0, len(videos) - 1, n_videos).astype(int)\n",
    "    videos = videos[idxs,:]\n",
    "\n",
    "    strm = '<h2>{}<h2>'.format(title)\n",
    "    for video_path, meta_path in videos:\n",
    "        video = io.open(video_path, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "\n",
    "        with open(meta_path) as data_file:    \n",
    "            meta = json.load(data_file)\n",
    "\n",
    "        html_tag = \"\"\"\n",
    "        <h3>{0}<h3/>\n",
    "        <video width=\"960\" height=\"540\" controls>\n",
    "            <source src=\"data:video/mp4;base64,{1}\" type=\"video/mp4\" />\n",
    "        </video>\"\"\"\n",
    "        strm += html_tag.format('Episode ' + str(meta['episode_id']), encoded.decode('ascii'))\n",
    "    return strm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gif_html(env_videos, title, max_n_videos=3):\n",
    "    videos = np.array(env_videos)\n",
    "    n_videos = min(max_n_videos, len(videos))\n",
    "    idxs = np.linspace(0, len(videos) - 1, n_videos).astype(int)\n",
    "    videos = videos[idxs,:]\n",
    "\n",
    "    strm = '<h2>{}<h2>'.format(title)\n",
    "    for video_path, meta_path in videos:\n",
    "        basename = os.path.splitext(video_path)[0]\n",
    "        gif_path = basename + '.gif'\n",
    "        if not os.path.exists(gif_path):\n",
    "            ps = subprocess.Popen(\n",
    "                ('ffmpeg', \n",
    "                 '-i', video_path, \n",
    "                 '-r', '10', \n",
    "                 '-f', 'image2pipe', \n",
    "                 '-vcodec', 'ppm', \n",
    "                 '-'), \n",
    "                stdout=subprocess.PIPE)\n",
    "            output = subprocess.check_output(\n",
    "                ('convert', \n",
    "                 '-delay', '5', \n",
    "                 '-loop', '0', \n",
    "                 '-', gif_path), \n",
    "                stdin=ps.stdout)\n",
    "            ps.wait()\n",
    "\n",
    "        gif = io.open(gif_path, 'r+b').read()\n",
    "        encoded = base64.b64encode(gif)\n",
    "            \n",
    "        with open(meta_path) as data_file:    \n",
    "            meta = json.load(data_file)\n",
    "\n",
    "        html_tag = \"\"\"\n",
    "        <h3>{0}<h3/>\n",
    "        <img src=\"data:image/gif;base64,{1}\" />\"\"\"\n",
    "        strm += html_tag.format('Episode ' + str(meta['episode_id']), encoded.decode('ascii'))\n",
    "    return strm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCP(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 output_dim,\n",
    "                 hidden_dims=(32,32), \n",
    "                 init_weight=3e-3,\n",
    "                 activation_fc=F.relu):\n",
    "        super(FCP, self).__init__()\n",
    "        self.activation_fc = activation_fc\n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, \n",
    "                                     hidden_dims[0])\n",
    "        \n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            hidden_layer = nn.Linear(\n",
    "                hidden_dims[i], hidden_dims[i+1])\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "                \n",
    "        self.output_layer = nn.Linear(\n",
    "            hidden_dims[-1], output_dim)\n",
    "        \n",
    "        device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda:0\"\n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "        \n",
    "        self.output_layer.weight.data.uniform_(\n",
    "            -init_weight, init_weight)\n",
    "        self.output_layer.bias.data.uniform_(\n",
    "            -init_weight, init_weight)\n",
    "\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = state\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, \n",
    "                             device=self.device, \n",
    "                             dtype=torch.float32)\n",
    "            x = x.unsqueeze(0)\n",
    "        x = self.activation_fc(self.input_layer(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation_fc(hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        action = self.forward(state)\n",
    "        action = action.detach().cpu().numpy()[0]\n",
    "        return action\n",
    "\n",
    "    def numpy_float_to_device(self, variable):\n",
    "        variable = torch.from_numpy(variable).float().to(self.device)\n",
    "        return variable\n",
    "    \n",
    "    def load_experiences(self, experiences):\n",
    "        states, actions, new_states, rewards, is_terminals = experiences\n",
    "        states = torch.from_numpy(states).float().to(self.device)\n",
    "        actions = torch.from_numpy(actions).float().to(self.device)\n",
    "        new_states = torch.from_numpy(new_states).float().to(self.device)\n",
    "        rewards = torch.from_numpy(rewards).float().to(self.device)\n",
    "        is_terminals = torch.from_numpy(is_terminals).float().to(self.device)\n",
    "        return states, actions, new_states, rewards, is_terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
